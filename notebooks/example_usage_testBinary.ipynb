{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Binary Mask\n",
    "\n",
    "For training, we will store the relative path information for each image and its masks within a dataframe with the following structure:\n",
    "\n",
    "|   images                                                                    |   masks                                               |   train  |\n",
    "|-----------------------------------------------------------------------------|-------------------------------------------------------|----------|\n",
    "|   ./data/images_stacked_channels/mx85-nd-acqusition-0-stacked-channels.tif  |   ./data/masks/mx85-nd-acqusition-0-ground-truth.tif  |   TRUE   |\n",
    "|   ./data/images_stacked_channels/mx85-nd-acqusition-1-stacked-channels.tif  |   ./data/masks/mx85-nd-acqusition-1-ground-truth.tif  |   TRUE   |\n",
    "|   ./data/images_stacked_channels/mx85-nd-acqusition-8-stacked-channels.tif  |   ./data/masks/mx85-nd-acqusition-8-ground-truth.tif  |   FALSE  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir(\"../\") # Root of repo\n",
    "#os.chdir(\"/Users/llanos/Documents/UNet_3D_C_elegans/\") # Root of repo\n",
    "import pandas as pd\n",
    "import unet.utils.data_utils as utils\n",
    "from unet.utils.load_data import CElegansDataset\n",
    "from unet.networks.unet3d import UNet3D\n",
    "from unet.networks.unet3d import SingleConv\n",
    "import sklearn.model_selection\n",
    "from torch.utils.data import DataLoader\n",
    "from unet.utils.loss import WeightedBCELoss, WeightedBCEDiceLoss\n",
    "import unet.augmentations.augmentations as aug\n",
    "import torch\n",
    "from unet.utils.trainer import RunTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# Here we can easily change data parameters and model hyperparameters\n",
    "\n",
    "params = {\n",
    "    \"Normalize\": {\"per_channel\": True},\n",
    "    \"RandomContrastBrightness\": {\"p\": 0.5},\n",
    "    \"Flip\": {\"p\": 0.5},\n",
    "    \"RandomRot90\": {\"p\": 0.5, \"channel_axis\": 0},\n",
    "    \"RandomGuassianBlur\": {\"p\": 0.5},\n",
    "    \"RandomGaussianNoise\": {\"p\": 0.5},\n",
    "    \"RandomPoissonNoise\": {\"p\": 0.5},\n",
    "    \"ElasticDeform\": {\"sigma\":10, \"p\":0.5, \"channel_axis\": 0, \"mode\":\"mirror\"},\n",
    "    \"LabelsToEdges\": {\"connectivity\": 2, \"mode\":\"thick\"},\n",
    "    \"EdgeMaskWmap\": {\"edge_multiplier\":2, \"wmap_multiplier\":1, \"invert_wmap\":True},\n",
    "    \"LabelsToEdgesAndBinary\": {\"connectivity\": 2, \"mode\": \"thick\",\"blur\":2},\n",
    "    \"BinaryMaskWmap\": {\"edge_multiplier\":2, \"wmap_multiplier\":1, \"invert_wmap\":True},\n",
    "    \"BlurMasks\": {\"sigma\": 2},\n",
    "    \"ToTensor\": {},\n",
    "    \"batch_size\": 1,\n",
    "    \"epochs\": 2,\n",
    "    \"val_split\": 0.2,\n",
    "    \"patch_size\": (24, 200, 200),\n",
    "    \"create_wmap\": True, ##\n",
    "    \"lr\": 1e-2,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"in_channels\": 2,\n",
    "    \"out_channels\": 1,\n",
    "    \"scheduler_factor\": 0.2,\n",
    "    \"scheduler_patience\": 20,\n",
    "    \"scheduler_mode\": \"min\",\n",
    "    \"loss_function\": WeightedBCEDiceLoss,\n",
    "    # \"targets\": [[\"image\"], [\"mask\"]]\n",
    "    \"targets\": [[\"image\"], [\"mask\"], [\"weight_map\"]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_data = pd.read_csv(\"/Users/llanos/Documents/UNet_3D_C_elegans/data/data_stacked_channels_training.csv\")[0:2]\n",
    "source_data = pd.read_csv(\"./data/data_stacked_channels_training.csv\")[0:2]\n",
    "\n",
    "\n",
    "#isExist = os.path.exists('./data/data_stacked_channels_training.csv')\n",
    "#print(isExist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 1024, 584) (1, 113, 1024, 584) (1, 113, 1024, 584)\n",
      "(2, 24, 1024, 1024) (1, 24, 1024, 1024) (1, 24, 1024, 1024)\n",
      "labels shape: (1, 24, 200, 200)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only 2-D and 3-D images supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m CElegansDataset(data_csv\u001b[38;5;241m=\u001b[39mtrain_dataset, transforms\u001b[38;5;241m=\u001b[39mtrain_transforms, targets\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m], train_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#print(train_transforms['image'].shape)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m        \u001b[38;5;66;03m# o cualquier índice que quieras inspeccionar\u001b[39;00m\n\u001b[1;32m     44\u001b[0m image \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]     \u001b[38;5;66;03m# esto es un numpy array\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast transform shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/unet/utils/load_data.py:127\u001b[0m, in \u001b[0;36mCElegansDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    125\u001b[0m     sample \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m: mask}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/workspace/unet/augmentations/augmentations.py:38\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m     34\u001b[0m transforms_to_apply \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;28;01mif\u001b[39;00m need_to_run \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_always_apply_transforms()\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m transforms_to_apply:\n\u001b[0;32m---> 38\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mtr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/workspace/unet/augmentations/augmentations.py:140\u001b[0m, in \u001b[0;36mDualTransform.__call__\u001b[0;34m(self, targets, **data)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# If the key is a mask, apply that method\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Why apply them differently? Well, you don't want resizing of a binary\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# mask to have interpolation added, do you?\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m targets[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 140\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_to_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m targets[\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# Treat weight maps like a mask in terms of transformation\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     data[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_to_wmap(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m/workspace/unet/augmentations/augmentations.py:240\u001b[0m, in \u001b[0;36mLabelsToEdgesAndBinary.apply_to_mask\u001b[0;34m(self, mask)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_to_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, mask):\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_to_edges_and_binary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectivity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblur\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/unet/augmentations/aug_functional.py:183\u001b[0m, in \u001b[0;36mlabels_to_edges_and_binary\u001b[0;34m(labels, mode, connectivity, blur)\u001b[0m\n\u001b[1;32m    181\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 183\u001b[0m regions \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregionprops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(regions) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    185\u001b[0m     cell_edges \u001b[38;5;241m=\u001b[39m skimage\u001b[38;5;241m.\u001b[39msegmentation\u001b[38;5;241m.\u001b[39mfind_boundaries(labels, connectivity)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/skimage/measure/_regionprops.py:1251\u001b[0m, in \u001b[0;36mregionprops\u001b[0;34m(label_image, intensity_image, cache, coordinates, extra_properties)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Measure properties of labeled image regions.\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \n\u001b[1;32m   1005\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \n\u001b[1;32m   1248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_image\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly 2-D and 3-D images supported.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(label_image\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger):\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(label_image\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: Only 2-D and 3-D images supported."
     ]
    }
   ],
   "source": [
    "# Create patches of the dataset\n",
    "# This is performed prior to training since weight-map generation online at train time is \n",
    "# computationally slow\n",
    "utils.create_patch_dataset(source_data, patch_size=params[\"patch_size\"], create_wmap=params[\"create_wmap\"])\n",
    "\n",
    "# Load the patch dataframe\n",
    "training_data = pd.read_csv(\"training_data.csv\")\n",
    "\n",
    "# Create the train/val split\n",
    "train_dataset, val_dataset = sklearn.model_selection.train_test_split(\n",
    "        training_data, test_size=params[\"val_split\"]\n",
    "        )\n",
    "\n",
    "# Define the augmentations for training and validation\n",
    "train_transforms = [\n",
    "    aug.Normalize(**params[\"Normalize\"]),\n",
    "    aug.RandomContrastBrightness(**params[\"RandomContrastBrightness\"]),\n",
    "    aug.Flip(**params[\"Flip\"]),\n",
    "    aug.RandomRot90(**params[\"RandomRot90\"]),\n",
    "    aug.RandomGuassianBlur(**params[\"RandomGuassianBlur\"]),\n",
    "    aug.RandomGaussianNoise(**params[\"RandomGaussianNoise\"]),\n",
    "    aug.RandomPoissonNoise(**params[\"RandomPoissonNoise\"]),\n",
    "    aug.ElasticDeform(**params[\"ElasticDeform\"]),\n",
    "    aug.LabelsToEdgesAndBinary(**params[\"LabelsToEdgesAndBinary\"]),\n",
    "    #aug.LabelsToEdges(**params[\"LabelsToEdges\"]),\n",
    "    #aug.EdgeMaskWmap(**params[\"EdgeMaskWmap\"]),\n",
    "    #aug.BlurMasks(**params[\"BlurMasks\"]),\n",
    "    #aug.ToTensor()\n",
    "]\n",
    "\n",
    "val_transforms = [\n",
    "    aug.Normalize(**params[\"Normalize\"]),\n",
    "    aug.LabelsToEdges(**params[\"LabelsToEdges\"]),\n",
    "    aug.EdgeMaskWmap(**params[\"EdgeMaskWmap\"]),\n",
    "    aug.BlurMasks(**params[\"BlurMasks\"]),\n",
    "    aug.ToTensor()\n",
    "]\n",
    "\n",
    "#print(train_transforms['image'].shape)\n",
    "train_ds = CElegansDataset(data_csv=train_dataset, transforms=train_transforms, targets=params[\"targets\"], train_val=\"train\")\n",
    "\n",
    "#print(train_transforms['image'].shape)\n",
    "output = train_ds[0]        # o cualquier índice que quieras inspeccionar\n",
    "image = output['image']     # esto es un numpy array\n",
    "print(f'last transform shape: {image.shape}')\n",
    "val_ds = CElegansDataset(data_csv=val_dataset, transforms=val_transforms, targets=params[\"targets\"], train_val=\"val\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "075cd4bb222163fe48208781b096772c7401b0a6e7eac05801f0c77158161f08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ctromans/miniconda3/envs/maddox-dbp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import skimage\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "import os\n",
    "import pathlib\n",
    "os.chdir(\"/Users/ctromans/image-analysis/UNet_3D_C_elegans/data/\")\n",
    "\n",
    "from unet.utils.data_utils import generate_patches, save_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a patch dataset\n",
    "# Basically, the ground truth is large 3D images (24, 1024, 1024) (z, y, x), so instead of generating patches on the fly\n",
    "# before feeding to the model, this will allow for batching of different patches to be passed and hopefully \n",
    "# better model performance.\n",
    "\n",
    "load_data = pd.read_csv(\"./data/data.csv\")\n",
    "\n",
    "patch_shape = (24, 200, 200)\n",
    "stride_shape = (24, 100, 100)\n",
    "\n",
    "save_df = {\n",
    "    \"image\": [],\n",
    "    \"label\": []\n",
    "    }\n",
    "\n",
    "for im, ma in zip(load_data.iloc[:, 0].values, load_data.iloc[:, 2].values):\n",
    "    image = torch.from_numpy(skimage.io.imread(im).astype(np.float32))\n",
    "    image_filename = os.path.basename(im)\n",
    "    image_patches = generate_patches(image, patch_shape=patch_shape, stride_shape=stride_shape)\n",
    "    image_save_paths = save_patches(image_patches, image_filename, \"./patch_data/image\")\n",
    "\n",
    "    save_df[\"image\"].extend(image_save_paths)\n",
    "\n",
    "    mask = torch.from_numpy(skimage.io.imread(ma).astype(np.float32))\n",
    "    mask_filename = os.path.basename(ma)\n",
    "    mask_patches = generate_patches(mask, patch_shape=patch_shape, stride_shape=stride_shape)\n",
    "    mask_save_paths = save_patches(mask_patches, mask_filename, \"./patch_data/labels\")\n",
    "\n",
    "    save_df[\"label\"].extend(mask_save_paths)\n",
    "\n",
    "save_df = pd.DataFrame.from_dict(save_df, orient=\"index\").transpose()\n",
    "save_df.to_csv(\"./patch_data/load_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new DF that excludes acquisition 1, which will be used for testing\n",
    "\n",
    "df = pd.read_csv(\"../patch_data/load_data.csv\")\n",
    "\n",
    "df = df[~df[\"image\"].str.contains(\"acqusition-1\")]\n",
    "\n",
    "df.to_csv(\"../patch_data/load_data_training.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make multichannel patches with shape (c, z, spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rw/691cc6h16f9cfxlh9g6bpq400000gq/T/ipykernel_13409/417812795.py:27: UserWarning: ./images_stacked_channels/mx85-nd-acqusition-0-stacked-channels.tif is a low contrast image\n",
      "  skimage.io.imsave(save_path, stacked_img)\n",
      "/var/folders/rw/691cc6h16f9cfxlh9g6bpq400000gq/T/ipykernel_13409/417812795.py:27: UserWarning: ./images_stacked_channels/mx85-nd-acqusition-1-stacked-channels.tif is a low contrast image\n",
      "  skimage.io.imsave(save_path, stacked_img)\n",
      "/var/folders/rw/691cc6h16f9cfxlh9g6bpq400000gq/T/ipykernel_13409/417812795.py:27: UserWarning: ./images_stacked_channels/mx85-nd-acqusition-8-stacked-channels.tif is a low contrast image\n",
      "  skimage.io.imsave(save_path, stacked_img)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/Users/ctromans/image-analysis/UNet_3D_C_elegans/data/\")\n",
    "import skimage\n",
    "\n",
    "df = pd.read_csv(\"/Users/ctromans/image-analysis/UNet_3D_C_elegans/data/data.csv\")\n",
    "\n",
    "ch1_list, ch2_list = df.iloc[:, 0], df.iloc[:, 1]\n",
    "\n",
    "save_dir = \"./images_stacked_channels/\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "stacked_df = {\n",
    "    \"images\": [],\n",
    "    \"masks\": df.iloc[:, 2].values\n",
    "}\n",
    "\n",
    "img_list = []\n",
    "\n",
    "for ch1, ch2 in zip(ch1_list, ch2_list):\n",
    "    # Quick and dirty way to reconstruct filename\n",
    "    filename = os.path.basename(ch1).rsplit(\"-\", 1)[0] + \"-stacked-channels.\" + os.path.basename(ch1).split(\".\")[-1]\n",
    "    ch1_img, ch2_img = skimage.io.imread(ch1), skimage.io.imread(ch2)\n",
    "    stacked_img = np.stack([ch1_img, ch2_img], axis=0)\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    skimage.io.imsave(save_path, stacked_img)\n",
    "    img_list.append(save_path)\n",
    "\n",
    "stacked_df[\"images\"] = img_list\n",
    "\n",
    "stacked_df = pd.DataFrame.from_dict(stacked_df)\n",
    "stacked_df.to_csv(\"/Users/ctromans/image-analysis/UNet_3D_C_elegans/data/data_stacked_channels.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make multichannel patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from unet.utils.data_utils import generate_patches, save_patches\n",
    "\n",
    "\n",
    "load_data = pd.read_csv(\"data_stacked_channels.csv\")\n",
    "\n",
    "patch_shape = (24, 200, 200)\n",
    "stride_shape = (24, 100, 100)\n",
    "\n",
    "save_df = {\n",
    "    \"images\": [],\n",
    "    \"masks\": []\n",
    "    }\n",
    "\n",
    "for im, ma in zip(load_data.iloc[:, 0].values, load_data.iloc[:, 1].values):\n",
    "    image = torch.from_numpy(skimage.io.imread(im).astype(np.float32))\n",
    "    image_filename = os.path.basename(im)\n",
    "    image_patches = generate_patches(image, patch_shape=patch_shape, stride_shape=stride_shape, unfold_dims=[1, 2, 3])\n",
    "    print(image_patches.shape)\n",
    "    image_save_paths = save_patches(image_patches, image_filename, \"./patch_data_stacked_channels/images\", patch_dim=1)\n",
    "\n",
    "    save_df[\"images\"].extend(image_save_paths)\n",
    "\n",
    "    mask = torch.from_numpy(skimage.io.imread(ma).astype(np.float32))\n",
    "    mask_filename = os.path.basename(ma)\n",
    "    # Mask can use default unfold dims\n",
    "    mask_patches = generate_patches(mask, patch_shape=patch_shape, stride_shape=stride_shape)\n",
    "    print(mask_patches.shape)\n",
    "    mask_save_paths = save_patches(mask_patches, mask_filename, \"./patch_data_stacked_channels/masks\", patch_dim=0)\n",
    "\n",
    "    save_df[\"masks\"].extend(mask_save_paths)\n",
    "\n",
    "save_df = pd.DataFrame.from_dict(save_df, orient=\"index\").transpose()\n",
    "save_df.to_csv(\"./patch_data_stacked_channels/load_data_stacked_channels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new DF that excludes acquisition 1, which will be used for testing\n",
    "\n",
    "df = pd.read_csv(\"./patch_data_stacked_channels/load_data_stacked_channels.csv\")\n",
    "\n",
    "df = df[~df[\"images\"].str.contains(\"acqusition-1\")]\n",
    "\n",
    "df.to_csv(\"./patch_data_stacked_channels/load_data_stacked_channels_training.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maddox-dbp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "075cd4bb222163fe48208781b096772c7401b0a6e7eac05801f0c77158161f08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
